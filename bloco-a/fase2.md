# Fase 2 ‚Äî DataOps: Ingest√£o & Indexa√ß√£o

---

## üß≠ Breadcrumb

Home ‚Üí Livro T√©cnico ‚Üí **Fase 2 ‚Äî DataOps: Ingest√£o & Indexa√ß√£o**

---

## üìå Sum√°rio da Fase 2

1. [Vis√£o geral da Fase 2](#1-vis√£o-geral-da-fase-2)
2. [Modelo de dados para pol√≠ticas (n√≠vel DataOps)](#2-modelo-de-dados-para-pol√≠ticas-n√≠vel-dataops)
3. [Fontes de dados & extra√ß√£o](#3-fontes-de-dados--extra√ß√£o)
4. [Landing Zone (raw) no Data Lake](#4-landing-zone-raw-no-data-lake)
5. [Pipeline de extra√ß√£o com Azure AI Document Intelligence](#5-pipeline-de-extra√ß√£o-com-azure-ai-document-intelligence)
6. [Normaliza√ß√£o e prepara√ß√£o para chunking](#6-normaliza√ß√£o-e-prepara√ß√£o-para-chunking)
7. [Estrat√©gia de chunking](#7-estrat√©gia-de-chunking)
8. [Enriquecimento com metadados](#8-enriquecimento-com-metadados)
9. [Persist√™ncia dos dados processados](#9-persist√™ncia-dos-dados-processados)
10. [Indexa√ß√£o em Azure AI Search](#10-indexa√ß√£o-em-azure-ai-search)
11. [Data Quality & QA da Fase 2](#11-data-quality--qa-da-fase-2)
12. [Tratamento de erros e retries](#12-tratamento-de-erros-e-retries)
13. [Performance & escalabilidade do pipeline](#13-performance--escalabilidade-do-pipeline)
14. [Seguran√ßa & compliance no pipeline de dados](#14-seguran√ßa--compliance-no-pipeline-de-dados)
15. [Orquestra√ß√£o DataOps (DAG, jobs, ambientes)](#15-orquestra√ß√£o-dataops-dag-jobs-ambientes)
16. [Versionamento de dados e lineage](#16-versionamento-de-dados-e-lineage)
17. [Observabilidade & monitoramento (DataOps)](#17-observabilidade--monitoramento-dataops)
18. [Artefatos da Fase 2 & Gate de sa√≠da](#18-artefatos-da-fase-2--gate-de-sa√≠da)

---
---
# 1. Vis√£o geral da Fase 2

A Fase 2 √© onde o Assistente de Pol√≠ticas deixa de ser apenas "um agente inteligente" e passa a ser suportado por uma funda√ß√£o s√≥lida de **DataOps**. O objetivo √© garantir que o agente **n√£o invente pol√≠ticas**, porque opera sobre uma base de dados robusta, versionada, audit√°vel e monitorada.

### üéØ Objetivo macro

Criar um pipeline de dados robusto que:

* Ingere pol√≠ticas oficiais de m√∫ltiplas fontes (SharePoint, file server, portais legados etc.).
* Armazena tudo em um **data lake organizado** (`raw ‚Üí extracted ‚Üí processed`).
* Extrai texto e estrutura com **Azure AI Document Intelligence**.
* Normaliza, limpa, organiza em **chunks** e enriquece com metadados de neg√≥cio e t√©cnicos.
* Indexa os dados em **Azure AI Search** com suporte completo a RAG (texto + vetores).
* Monitora **qualidade, cobertura e falhas** em n√≠vel de documento e chunk.

### ‚úÖ Condi√ß√£o de ‚ÄúFase 2 conclu√≠da‚Äù

A fase √© considerada conclu√≠da quando:

* 100% das pol√≠ticas do invent√°rio da Fase 0 est√£o:

  * Ingeridas (raw),
  * Extra√≠das (texto + layout),
  * Normalizadas e chunkadas,
  * Indexadas em Azure AI Search.
* Existem m√©tricas claras de:

  * **Coverage** (documentos e chunks),
  * **Qualidade de extra√ß√£o** (golden set),
  * **Atualiza√ß√£o** (tempo entre altera√ß√£o e disponibilidade).
* Os pipelines s√£o **reprodut√≠veis**, **versionados** e possuem logs + alertas.

---
---
# 2. Modelo de dados para pol√≠ticas (n√≠vel DataOps)

Antes de falar de pipelines, definimos **como os dados ser√£o representados** ao longo do fluxo.

## 2.1 Entidades de dados

* **PolicySource** ‚Äì Origem bruta (SharePoint, file server, portal, e-mail).
* **PolicyDocument** ‚Äì Documento l√≥gico de pol√≠tica (ex.: ‚ÄúPol√≠tica de F√©rias‚Äù).
* **PolicyVersion** ‚Äì Vers√£o espec√≠fica de um documento (v3.1, v4.0‚Ä¶).
* **PolicyChunk** ‚Äì Trecho de texto usado no RAG (unidade m√≠nima index√°vel).
* **PolicyIndexRecord** ‚Äì Representa√ß√£o final, pronta para Azure AI Search.

### üßä Diagrama conceitual de dados

```mermaid
erDiagram
    POLICY_SOURCE ||--o{ POLICY_DOCUMENT : provides
    POLICY_DOCUMENT ||--o{ POLICY_VERSION : has
    POLICY_VERSION ||--o{ POLICY_CHUNK : contains
    POLICY_CHUNK ||--o{ POLICY_INDEX_RECORD : materializes

    POLICY_SOURCE {
        string id
        string system
        string path
    }
    POLICY_DOCUMENT {
        string policy_id
        string title
        string area
        string owner
        string sensitivity_level
    }
    POLICY_VERSION {
        string policy_version_id
        string policy_id
        string version
        string status
        date effective_from
        date effective_to
        string source_system
        string source_path
        string hash_raw_file
    }
    POLICY_CHUNK {
        string chunk_id
        string policy_version_id
        int chunk_index
        string section_title
        string section_hierarchy
        string content
    }
```

## 2.2 Esquema l√≥gico (quase f√≠sico)

### Tabela `policy_documents`

* `policy_id` (PK) ‚Äì Ex.: `POL-RH-FERIAS`.
* `title` ‚Äì Nome da pol√≠tica.
* `area` ‚Äì RH, Jur√≠dico, Seguran√ßa, etc.
* `owner` ‚Äì Pessoa/√°rea respons√°vel.
* `description` ‚Äì Resumo curto.
* `sensitivity_level` ‚Äì `INTERNAL | INTERNAL_RESTRICTED | CONFIDENTIAL`.
* `created_at`, `updated_at`.

### Tabela `policy_versions`

* `policy_version_id` (PK, uuid).
* `policy_id` (FK ‚Üí `policy_documents`).
* `version` ‚Äì Ex.: `"3.1"`.
* `status` ‚Äì `DRAFT | ACTIVE | DEPRECATED`.
* `effective_from`, `effective_to` (nullable).
* `source_system` ‚Äì SHAREPOINT, FILESYSTEM, etc.
* `source_path` ‚Äì URL/caminho do arquivo.
* `hash_raw_file` ‚Äì Checksum para detectar mudan√ßas.
* `ingested_at`, `extracted_at`, `processed_at`, `indexed_at`.

### Tabela `policy_chunks`

* `chunk_id` (PK, uuid).
* `policy_version_id` (FK).
* `chunk_index` ‚Äì Ordem do chunk no documento.
* `section_hierarchy` ‚Äì Ex.: `["1. Objetivo", "1.2 Escopo"]`.
* `section_title` ‚Äì T√≠tulo da se√ß√£o principal.
* `content` ‚Äì Texto puro, limpo.
* `tokens_count` ‚Äì N¬∫ de tokens aproximado.
* `language` ‚Äì Ex.: `"pt-BR"`.
* `sensitivity_level` ‚Äì Repetido para facilitar filtros.
* `created_at`.

> **Observa√ß√£o:** a embedding pode ficar numa coluna separada (para DBs com suporte vetorial) ou ser calculada na etapa de indexa√ß√£o do Azure AI Search.

## 2.3 √çndice `policy-index` no Azure AI Search

Campos essenciais:

* `id` ‚Äì `chunk_id`.
* `policy_id`, `policy_version`, `policy_title`.
* `area`, `sensitivity_level`.
* `effective_from`, `effective_to`.
* `section_title`, `section_hierarchy`.
* `content`.
* `source_url`.
* `language`.
* `embedding` ‚Äì Campo vetorial.

---
---
# 3. Fontes de dados & extra√ß√£o

## 3.1 Tipos de fontes

* **SharePoint / OneDrive / Teams** ‚Äì Bibliotecas de documentos (PDF, DOCX).
* **File Server on-prem** ‚Äì Diret√≥rios de pol√≠ticas antigas.
* **Sistemas legados / Portais** ‚Äì P√°ginas HTML exportadas.
* **E-mails hist√≥ricos (opcional)** ‚Äì Comunicados importantes convertidos em documentos.

## 3.2 Padr√µes de ingest√£o

* **Full Load inicial**:

  * Ingesta todas as pol√≠ticas listadas no invent√°rio da Fase 0 para `raw/`.
* **Incremental (delta)**:

  * Executado periodicamente (por exemplo, 1x/dia).
  * Detecta novos arquivos e mudan√ßas via `hash_raw_file`.

## 3.3 Conectores concretos

* **SharePoint**:

  * Azure Data Factory com conector nativo ou
  * Scripts Python usando Microsoft Graph API.
* **File Server**:

  * Data Factory com Self-hosted Integration Runtime ou
  * Servi√ßo on-prem que envia para Blob Storage.
* **Outros sistemas**:

  * APIs HTTP ‚Üí pipelines Data Factory/Airflow/n8n.

## 3.4 Metadados na ingest√£o

Ao mover um arquivo para `raw/`, registrar:

* `source_system`, `source_path`.
* `policy_id` (se j√° mapeado) ou identificador tempor√°rio.
* `ingested_on`.
* `hash_raw_file`.

---
---
# 4. Landing Zone (raw) no Data Lake

Estrutura recomendada em Blob Storage / ADLS Gen2:

```text
/policies/
  raw/
    sharepoint/
      RH/
        POL-RH-FERIAS/
          POL-RH-FERIAS_v3.1_20240101.pdf
      Juridico/
      Seguranca/
    filesystem/
    ...
  extracted/
    ... (JSON + texto extra√≠do)
  processed/
    chunks/
      year=2024/month=01/
        POL-RH-FERIAS_v3.1_chunk_0001.json
        POL-RH-FERIAS_v3.1_chunk_0002.json
```

### Conven√ß√µes de nomes

* Arquivo raw: `<policy_id>_v<version>_<effective_from>.ext`.
* Metadados do Blob:

  * `x-policy-id`, `x-policy-version`, `x-area`, `x-sensitivity`.

Essas conven√ß√µes facilitam:

* Auditoria.
* Reprocessamento seletivo.
* Filtros por √°rea/sensibilidade no pr√≥prio armazenamento.

---
---
# 5. Pipeline de extra√ß√£o com Azure AI Document Intelligence

## 5.1 Escolha de modelo

* **Modelos pr√©-treinados**:

  * `prebuilt-document` para documentos gerais.
* **Modelos customizados** (se layout for padronizado):

  * Extraem campos espec√≠ficos (ex.: ‚ÄúObjetivo‚Äù, ‚ÄúEscopo‚Äù, ‚ÄúDefini√ß√µes‚Äù).

## 5.2 Fluxo de extra√ß√£o

Para cada arquivo em `raw/`:

1. Ler do Blob.
2. Enviar para Document Intelligence.
3. Receber:

   * Texto completo.
   * Layout (p√°ginas, par√°grafos, tabelas, se√ß√µes).
   * Estrutura em JSON.
4. Persistir em `extracted/`:

   * `*.json` com estrutura completa.
   * `*.txt` opcional com texto linear.

## 5.3 Tratamento de formatos

* **PDF**:

  * Aten√ß√£o a colunas, cabe√ßalhos/rodap√©s repetidos.
* **DOCX**:

  * Converter para PDF ou enviar direto, se suportado.
* **Imagens (scans)**:

  * OCR nativo do servi√ßo.
  * Maior esfor√ßo de QA.

## 5.4 Limpeza p√≥s-extra√ß√£o

Regras t√≠picas:

* Remover cabe√ßalhos/rodap√©s repetitivos.
* Normalizar quebras de linha para par√°grafos coerentes.
* Remover caracteres estranhos (NBSP, etc.).
* Padronizar listas, bullets e numera√ß√µes.

---
---
# 6. Normaliza√ß√£o e prepara√ß√£o para chunking

## 6.1 Identifica√ß√£o de se√ß√µes

A partir do JSON de Document Intelligence:

* Detectar headings por:

  * Padr√µes `1.`, `1.1`, `1.1.1` etc.
  * Estilo tipogr√°fico (H1, H2, negrito, tamanho).
* Construir uma **√°rvore de se√ß√µes** com t√≠tulo, n√∫mero e texto.

### Exemplo de √°rvore

```json
{
  "title": "Pol√≠tica de F√©rias",
  "sections": [
    {
      "number": "1",
      "title": "Objetivo",
      "text": "...",
      "children": []
    },
    {
      "number": "2",
      "title": "Elegibilidade",
      "text": "...",
      "children": [
        {
          "number": "2.1",
          "title": "Colaboradores CLT",
          "text": "...",
          "children": []
        }
      ]
    }
  ]
}
```

## 6.2 Corre√ß√µes semi-autom√°ticas

Heur√≠sticas:

* Par√°grafos iniciados por `a)`, `b)`, `c)` ‚Üí herdarem o heading anterior.
* Juntar par√°grafos quebrados por diagrama√ß√£o.

## 6.3 Limpeza de PII (opcional)

Se houver exemplos com dados pessoais:

* Detectar PII via Azure Cognitive Services ou regex.
* Substituir por placeholders (`<NOME>`, `<CPF>` etc.).

---
---
# 7. Estrat√©gia de chunking

## 7.1 Objetivos

Cada **PolicyChunk** deve:

* Fazer sentido sozinho.
* Ser espec√≠fico o suficiente para perguntas pontuais.
* N√£o ‚Äúexplodir‚Äù tokens.
* Preservar contexto de se√ß√£o/hierarquia.

## 7.2 Abordagens

### Modo A ‚Äî Chunk por se√ß√£o com limite de tokens

* Para cada se√ß√£o:

  * Concatenar par√°grafos at√© `min_tokens` (ex.: 100).
  * N√£o ultrapassar `max_tokens` (ex.: 400‚Äì500).
  * Se ultrapassar, dividir respeitando par√°grafos/frases.

### Modo B ‚Äî Sliding window

* Usar janela deslizante com sobreposi√ß√£o:

  * `max_tokens = 400`, `overlap = 80`.
* Vantagens:

  * Mais contexto, por√©m mais custo (mais chunks).

## 7.3 Campos do chunk

* `chunk_id`
* `policy_version_id`
* `chunk_index`
* `section_hierarchy`
* `section_title`
* `content`
* `tokens_count`
* `sensitivity_level`
* `effective_from`, `effective_to`
* `source_url`

## 7.4 Pseudo-algoritmo de chunking

```python
for policy_version in ACTIVE_POLICIES:
    sections_tree = parse_sections(policy_version.extracted_json)
    chunk_index = 0
    for section in sections_tree:
        buffer = ""
        buffer_tokens = 0
        for paragraph in section.paragraphs:
            tokens = count_tokens(paragraph)
            if buffer_tokens + tokens > MAX_TOKENS:
                yield_chunk(policy_version, section, chunk_index, buffer)
                chunk_index += 1
                buffer = paragraph
                buffer_tokens = tokens
            else:
                buffer += "\n" + paragraph
                buffer_tokens += tokens
        if buffer:
            yield_chunk(policy_version, section, chunk_index, buffer)
            chunk_index += 1
```
---
---

# 8. Enriquecimento com metadados

## 8.1 Metadados de neg√≥cio (da Fase 0)

V√™m do invent√°rio de pol√≠ticas:

* `policy_id`, `title`, `area`, `owner`.
* `sensitivity_level`.
* `effective_from`, `effective_to`.

S√£o propagados para:

* `policy_versions`.
* `policy_chunks`.
* `policy_index` (Azure Search).

## 8.2 Metadados t√©cnicos

* `hash_raw_file`.
* `extraction_engine_version` (ex.: `docAI_v2025-01`).
* `chunking_algorithm_version` (ex.: `chunk_v1.2`).
* `pipeline_run_id` (identificador do job).

Isso permite:

* Saber qual vers√£o de algoritmo gerou cada chunk.
* Refazer indexa√ß√£o de forma seletiva quando o algoritmo evoluir.

---
---
# 9. Persist√™ncia dos dados processados

## 9.1 Formatos f√≠sicos

Recomendado:

* **Parquet** para an√°lises (Spark/Synapse).
* **JSONL** para indexa√ß√£o.

Exemplo:

```text
processed/
  chunks/
    year=2025/month=01/
      policy_chunks_20250101.parquet
      policy_chunks_20250101.jsonl
```

## 9.2 Estrutura JSONL para indexa√ß√£o

Cada linha representa um `PolicyIndexRecord`:

```json
{
  "id": "chunk-uuid",
  "policy_id": "POL-RH-FERIAS",
  "policy_version": "3.1",
  "policy_title": "Pol√≠tica de F√©rias",
  "area": "RH",
  "sensitivity_level": "INTERNAL",
  "effective_from": "2024-01-01",
  "effective_to": null,
  "section_title": "Direito a f√©rias",
  "section_hierarchy": ["2. Elegibilidade", "2.1 Colaboradores CLT"],
  "content": "Texto completo do chunk...",
  "source_url": "https://.../POL-RH-FERIAS_v3.1.pdf",
  "language": "pt-BR",
  "embedding": null,
  "chunk_index": 5,
  "pipeline_run_id": "run-2025-01-10T10:00:00Z"
}
```
---
---

# 10. Indexa√ß√£o em Azure AI Search

## 10.1 Design do √≠ndice

* Nome: `policy-index-v1` (j√° pensando em vers√µes futuras).
* Campos:

  * `id` (key).
  * `policy_id`, `policy_title`, `policy_version`, `area`, `sensitivity_level`.
  * `effective_from`, `effective_to`.
  * `section_title`, `section_hierarchy`.
  * `content`, `source_url`, `language`.
  * `embedding` (campo vetorial).

## 10.2 Configura√ß√£o vetorial

* Algoritmo: **HNSW**.
* Dimens√£o: conforme o modelo de embedding.
* Modelo de embedding:

  * Ex.: `text-embedding-3-small` (Azure OpenAI).

## 10.3 Skillset & Indexer (Op√ß√£o A ‚Äì indexador autom√°tico)

* **Skillset**:

  * Skill de embedding que gera vetores a partir de `content`.
* **Indexer**:

  * Input: arquivos JSONL em `processed/chunks/`.
  * Output: `policy-index-v1`.
  * Schedule: por exemplo, a cada 1 hora.

## 10.4 Indexa√ß√£o ‚Äúpush‚Äù (Op√ß√£o B ‚Äì via c√≥digo)

* Pipeline l√™ Parquet/JSONL.
* Calcula embedding via Azure OpenAI.
* Usa a API de batch do Azure Search para enviar documentos.

## 10.5 Atualiza√ß√£o do √≠ndice

* Quando uma `policy_version` se torna `ACTIVE`:

  * Indexar seus chunks.
* Vers√µes `DEPRECATED`:

  * Remover do √≠ndice ou marcar como inativas.
* Regra base:

  * Somente `policy_versions` com `status = ACTIVE` entram no RAG.

---
---
# 11. Data Quality & QA da Fase 2

## 11.1 Testes por etapa do pipeline

1. **Ingest√£o (raw)**

   * Testes:

     * Todos os documentos do invent√°rio foram ingeridos?
     * Hash dos arquivos confere?
   * M√©tricas:

     * `coverage_policies_raw = docs_ingestados / docs_invent√°rio`.

2. **Extra√ß√£o (Document Intelligence)**

   * Testes:

     * Conjunto de documentos "golden".
     * Checar se o texto extra√≠do cobre > X% do texto original.
     * Verificar se headings principais foram detectados.

3. **Normaliza√ß√£o & chunking**

   * Testes:

     * Nenhum chunk com `content` vazio.
     * `tokens_count` dentro de um intervalo aceit√°vel.
     * Cada `policy_version` ativa tem pelo menos 1 chunk.

4. **Enriquecimento**

   * Testes:

     * Todos os chunks t√™m `policy_id`, `policy_version`, `sensitivity_level`, `effective_from`.
     * `effective_from <= effective_to` (se n√£o nulo).

5. **Indexa√ß√£o**

   * Testes:

     * N√∫mero de documentos no √≠ndice ‚âà n√∫mero de chunks processados (dentro de uma toler√¢ncia).
     * Buscar por `policy_id` e verificar retorno.

## 11.2 Golden set de QA

* Selecionar 3‚Äì5 pol√≠ticas cr√≠ticas (f√©rias, home office, jornada etc.).
* Validar manualmente, para cada uma:

  * Extra√ß√£o de texto.
  * Estrutura de se√ß√µes.
  * Chunks gerados.

## 11.3 M√©tricas de qualidade

* `coverage_policies = #policy_versions_indexadas / #policy_versions_ativas`.
* `coverage_chunks = #chunks_indexados / #chunks_processados`.
* `avg_chunk_length_tokens`.
* `golden_doc_extraction_score` (0‚Äì1).
* `golden_doc_chunk_quality_score` (0‚Äì1, avalia√ß√£o humana).

---
---
# 12. Tratamento de erros e retries

## 12.1 Tipos de erro

* Falha de conex√£o com fonte (SharePoint/file server).
* Erros da API do Document Intelligence.
* Documentos com layout corrompido/scans ruins.
* Falhas de grava√ß√£o em `processed/`.
* Falhas na indexa√ß√£o.

## 12.2 Estrat√©gia de resili√™ncia

* **Retries com backoff exponencial** para erros transit√≥rios.
* **Dead-letter / Quarantine** para documentos com falha repetida:

  * Mover para `quarantine/`.
  * Registrar em `failed_documents` (motivo, timestamp, tentativa).
* **Flags de status** em `policy_versions`:

  * `extraction_status`: `PENDING | OK | FAILED`.
  * `processing_status`.
  * `indexing_status`.

Isso permite:

* Identificar gargalos.
* Reprocessar apenas o que falhou.

---
---
# 13. Performance & escalabilidade do pipeline

## 13.1 Volume esperado

* N¬∫ de pol√≠ticas geralmente < 500.
* Tamanho m√©dio moderado, com atualiza√ß√µes pouco frequentes.

## 13.2 Estrat√©gias de escalabilidade

* **Paraleliza√ß√£o**:

  * Processar documentos em paralelo por √°rea ou pol√≠tica.
* **Batch vs streaming**:

  * Ingest√£o e indexa√ß√£o por lotes (batch di√°rio/hor√°rio).
* **Tuning de custo**:

  * Rodar extra√ß√£o apenas quando `hash_raw_file` mudar.
  * Reutilizar embeddings para chunks n√£o alterados.

---
---
# 14. Seguran√ßa & compliance no pipeline de dados

## 14.1 Governan√ßa de acesso

* Storage acessado com **Managed Identity**.
* Bloqueio de acesso an√¥nimo.
* Document Intelligence com chaves em **Key Vault**.
* Metadados acess√≠veis apenas por time de DataOps e aplica√ß√£o.

## 14.2 Logs & prote√ß√£o de dados sens√≠veis

* Evitar armazenar texto completo de pol√≠ticas confidenciais em logs.
* Quando necess√°rio, logar apenas:

  * Hash do documento.
  * Trechos truncados.
  * IDs e metadados, nunca conte√∫do completo.

---
---
# 15. Orquestra√ß√£o DataOps (DAG, jobs, ambientes)

## 15.1 Orquestrador

Ferramentas poss√≠veis:

* Azure Data Factory / Synapse Pipelines.
* Airflow.
* n8n.

Idealmente, escolher **um orquestrador principal** para o pipeline central.

## 15.2 DAG do pipeline

### Tarefas principais

1. `discover_new_documents`
2. `copy_to_raw`
3. `run_doc_intelligence`
4. `normalize_and_chunk`
5. `enrich_metadata`
6. `write_processed_data`
7. `index_to_azure_search`
8. `update_status_tables`
9. `run_data_quality_checks`

Cada tarefa deve:

* Ter retries configurados.
* Escrever logs detalhados.

### Diagrama de fluxo do pipeline (Mermaid)

```mermaid
flowchart TD
    A[discover_new_documents] --> B[copy_to_raw]
    B --> C[run_doc_intelligence]
    C --> D[normalize_and_chunk]
    D --> E[enrich_metadata]
    E --> F[write_processed_data]
    F --> G[index_to_azure_search]
    G --> H[update_status_tables]
    H --> I[run_data_quality_checks]
```

## 15.3 Ambientes

* **dev**: subset pequeno de pol√≠ticas.
* **staging**: espelho amplo do invent√°rio.
* **prod**: invent√°rio completo.

Configura√ß√µes (endpoints, √≠ndices, storage) segregadas por ambiente.

---
---

# 16. Versionamento de dados e lineage

## 16.1 Versionamento de documento e pipeline

Para cada `policy_version`, registrar:

* `pipeline_run_id`.
* `extraction_engine_version`.
* `chunking_algorithm_version`.
* `index_version` (ex.: `policy-index-v1`).

## 16.2 Lineage

Idealmente, usar um **Data Catalog** para registrar:

* Fonte ‚Üí raw ‚Üí extracted ‚Üí processed ‚Üí √≠ndice.

Perguntas que o lineage precisa responder:

* ‚ÄúEssa resposta do agente veio de qual vers√£o de pol√≠tica?‚Äù
* ‚ÄúQual run de pipeline gerou esses chunks?‚Äù

---
---

# 17. Observabilidade & monitoramento (DataOps)

## 17.1 M√©tricas

* `documents_ingested_count` (por dia).
* `documents_extracted_ok` vs `documents_extracted_failed`.
* `chunks_generated_count`.
* `index_documents_count`.
* `pipeline_latency` (tempo m√©dio para um documento ficar dispon√≠vel).
* `policy_coverage`.

## 17.2 Dashboards

Em Power BI / Grafana / Azure Monitor, criar pain√©is como:

* **Painel DataOps**:

  * N¬∫ de pol√≠ticas por status (PENDING, OK, FAILED).
  * Tempo m√©dio de extra√ß√£o.
  * Tempo entre upload e disponibiliza√ß√£o no √≠ndice.

* **Painel de qualidade**:

  * Score dos golden docs.
  * N¬∫ de documentos em `quarantine`.

## 17.3 Alertas

Disparar alertas quando:

* `policy_coverage < 95%`.
* Falhas de extra√ß√£o > X em 24h.
* √öltima execu√ß√£o bem-sucedida do pipeline > N horas.

---
---

# 18. Artefatos da Fase 2 & Gate de sa√≠da

## 18.1 Artefatos esperados

* `22-data-model-policies.md`

  * Tabelas/cole√ß√µes: `policy_documents`, `policy_versions`, `policy_chunks`.
* `23-datalake-layout.md`

  * Estrutura de pastas `raw/`, `extracted/`, `processed/`.
* `24-document-intelligence-spec.md`

  * Modelos, par√¢metros, exemplos de sa√≠da.
* `25-chunking-strategy.md`

  * Algoritmos, par√¢metros, diagramas.
* `26-azure-search-index-design.md`

  * Campos, tipos, configura√ß√µes vetoriais.
* `27-dataops-pipeline-dag.md`

  * DAG, depend√™ncias, regras de retry.
* `28-data-quality-tests.md`

  * Testes autom√°ticos, m√©tricas, golden set.
* `29-dataops-monitoring-and-alerts.md`
* `30-data-lineage-and-versioning.md`

## 18.2 Crit√©rios GO/NO-GO da Fase 2

### ‚úÖ GO se:

* Pelo menos **95% das `policy_versions` ativas** est√£o:

  * Ingeridas,
  * Extra√≠das,
  * Chunkadas,
  * Indexadas.
* O golden set atinge o **score m√≠nimo definido** para extra√ß√£o e chunking.
* O pipeline √©:

  * Reexecut√°vel,
  * Monitorado,
  * Com alertas configurados.
* Donos de pol√≠ticas (RH/Jur√≠dico/Seguran√ßa) validaram pelo menos **1‚Äì2 documentos por √°rea**.

### ‚ùå NO-GO se:

* H√° diverg√™ncia significativa entre invent√°rio e √≠ndice (pol√≠ticas "sumidas").
* Existem erros graves de extra√ß√£o em pol√≠ticas cr√≠ticas.
* N√£o h√° forma de monitorar novas vers√µes de pol√≠ticas ou detectar falhas do pipeline.

---

üëâ **Pr√≥ximo cap√≠tulo:** [Fase 3 ‚Äî Implementa√ß√£o do Backend, Agentes e API](#) (link ser√° ajustado para o arquivo `Fase3.md` quando criado).
